{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rastringer/ml_gke_notebooks/blob/main/introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv76sbm3U2IT"
      },
      "source": [
        "### Training a simple MNIST model on T4 GPU using GKE\n",
        "\n",
        "In this introductory notebook, we will create and run a simple model training job using a GPU on GKE.\n",
        "\n",
        "The MNIST database (Modified National Institute of Standards and Technology database) is a popular dataset for training image recognition and other machine learning models. It comprises 60,000 training images and 10,000 test images of handwritten digits, 0-9.\n",
        "\n",
        "As is common for container-based workloads, this code should be easily adapted to running elsewhere, either on a local kubernetes cluster or on another cloud.\n",
        "\n",
        "Note that you need a VPC Network and a subnet for the region you choose to use in your Google Cloud project\n",
        "\n",
        "### Authenticate to GCP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23lc27zkU0SH"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Adzxse4hVDFi"
      },
      "source": [
        "Let's make sure we have the Google Cloud CLI installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Z0KNFeSUygk"
      },
      "outputs": [],
      "source": [
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg |  gpg --dearmor -o /usr/share/keyrings/cloud.google.gpg\n",
        "\n",
        "!echo \"deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main\" |  tee -a /etc/apt/sources.list.d/google-cloud-sdk.list\n",
        "\n",
        "!apt-get update &&  apt-get install google-cloud-cli\n",
        "\n",
        "!apt-get update && apt-get install google-cloud-cli-gke-gcloud-auth-plugin\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jekg86nZWuOk"
      },
      "source": [
        "Here's how we can install `kubectl` in the Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEklYhgbWpOj"
      },
      "outputs": [],
      "source": [
        "! apt-get update && apt-get install -y apt-transport-https gnupg2\n",
        "! curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "! echo \"deb https://apt.kubernetes.io/ kubernetes-xenial main\" | tee -a /etc/apt/sources.list.d/kubernetes.list\n",
        "! apt-get update\n",
        "! apt-get install -y kubectl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSU8KWuGFo0s"
      },
      "source": [
        "### Set environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxB-7YsSFk6L"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"PROJECT_ID\"] = \"<your-project-id>\"\n",
        "os.environ[\"REGION\"] = \"us-central1\"\n",
        "os.environ[\"ZONE\"] = \"us-central1-a\"\n",
        "os.environ[\"BUCKET_NAME\"] = \"<your-bucket-name>\"\n",
        "os.environ[\"VPC_NAME\"] = \"default\"\n",
        "os.environ[\"VPC_SUBNET\"] = \"default\"\n",
        "os.environ[\"GCE_SA_EMAIL\"] = \"<your GCE SA email>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PNV4RsoFXVY"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = os.environ.get('PROJECT_ID')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_354g2oMSOZd"
      },
      "outputs": [],
      "source": [
        "! gcloud config set project $PROJECT_ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WrG8o2ETxLW"
      },
      "outputs": [],
      "source": [
        "! gcloud projects describe $PROJECT_ID --format=\"value(projectNumber)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eY8atHd7VOod"
      },
      "outputs": [],
      "source": [
        "# Enable APIs\n",
        "! gcloud services enable iam.googleapis.com\n",
        "! gcloud services enable container.googleapis.com\n",
        "! gcloud services enable cloudbuild.googleapis.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add necessary roles to the default GCE Service Account to be able to write logs, view metrics etc.\n",
        "! gcloud projects add-iam-policy-binding ${PROJECT_ID} --member=serviceAccount:${GCE_SA_EMAIL} --role=\"roles/logging.logWriter\"\n",
        "! gcloud projects add-iam-policy-binding ${PROJECT_ID} --member=serviceAccount:${GCE_SA_EMAIL} --role=\"roles/monitoring.metricWriter\"\n",
        "! gcloud projects add-iam-policy-binding ${PROJECT_ID} --member=serviceAccount:${GCE_SA_EMAIL} --role=\"roles/monitoring.viewer\"\n",
        "! gcloud projects add-iam-policy-binding ${PROJECT_ID} --member=serviceAccount:${GCE_SA_EMAIL} --role=\"roles/stackdriver.resourceMetadata.writer\"\n",
        "! gcloud projects add-iam-policy-binding ${PROJECT_ID} --member=serviceAccount:${GCE_SA_EMAIL} --role=\"roles/autoscaling.metricsWriter\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8tEBusj3uRH"
      },
      "source": [
        "### Create a GKE cluster\n",
        "\n",
        "There are many options when creating a GKE cluster, please see [here](https://cloud.google.com/sdk/gcloud/reference/container/clusters/create) for the full list.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYhS2ghP0Q-d"
      },
      "outputs": [],
      "source": [
        "! gcloud container clusters create t4-demo --location ${REGION} \\\n",
        "  --workload-pool ${PROJECT_ID}.svc.id.goog \\\n",
        "  --enable-image-streaming \\\n",
        "  --enable-shielded-nodes \\\n",
        "  --shielded-secure-boot \\\n",
        "  --shielded-integrity-monitoring \\\n",
        "  --enable-ip-alias \\\n",
        "  --node-locations=${ZONE} \\\n",
        "  --network projects/$PROJECT_ID/global/networks/${VPC_NAME} \\\n",
        "  --subnetwork ${VPC_SUBNET} \\\n",
        "  --workload-pool=${PROJECT_ID}.svc.id.goog \\\n",
        "  --labels=\"ml-on-gke=t4-demo\" \\\n",
        "  --addons GcsFuseCsiDriver"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-sXCUk33zi9"
      },
      "source": [
        "Now that we have a cluster, we need to add a node pool with the T4 GPUs. Create a [node pool](https://cloud.google.com/kubernetes-engine/docs/how-to/gpus) with T4 GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZvEEu793yfz"
      },
      "outputs": [],
      "source": [
        "! gcloud container node-pools create gpu-pool \\\n",
        "  --accelerator type=nvidia-tesla-t4,count=1,gpu-driver-version=default \\\n",
        "  --machine-type=n1-standard-2 \\\n",
        "  --num-nodes=2 \\\n",
        "  --region=${REGION} \\\n",
        "  --cluster=t4-demo \\\n",
        "  --node-locations ${ZONE}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xERpM8Cd8Vn-"
      },
      "source": [
        "###Set up the convolutional neural net\n",
        "\n",
        "Here's our simple convolutional neural network in PyTorch which we will use for some investigations on the MNIST dataset of hand-drawn numbers, 0-9. It consists of:\n",
        "\n",
        "* Two convolutional layers (conv1 and conv2)\n",
        "* Two dropout layers, used for regularization\n",
        "* Two fully connected layers - these 'flatten' outputs from the pervious layers and reduce the dimensions to the final output of 10 classes in this case (numerals 0-9)\n",
        "* The 'forward' methos defines the forward pass of data through the various layers, with ReLU activation, max-pooling and dropout to prevent overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGZ6Tiak9YAf"
      },
      "source": [
        "### Writefile\n",
        "\n",
        "We use `%%writefile`, a magic function for notebooks, to write our code to a file, `train.py` in this case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYhCYz6F-aFW"
      },
      "outputs": [],
      "source": [
        "%%writefile train.py\n",
        "\n",
        "\"\"\"\n",
        "Thanks to Meta for the PyTorch example at\n",
        "https://github.com/pytorch/examples/blob/main/mnist/main.py\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(9216, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % LOG_INTERVAL == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "EPOCHS = 1\n",
        "BATCH_SIZE = 64\n",
        "LR = 0.001\n",
        "GAMMA = 0.7\n",
        "SEED = 1\n",
        "LOG_INTERVAL = 100\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if use_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "train_kwargs = {'batch_size': BATCH_SIZE}\n",
        "test_kwargs = {'batch_size': BATCH_SIZE}\n",
        "if use_cuda:\n",
        "    cuda_kwargs = {'num_workers': 1,\n",
        "                    'pin_memory': True,\n",
        "                    'shuffle': True}\n",
        "    train_kwargs.update(cuda_kwargs)\n",
        "    test_kwargs.update(cuda_kwargs)\n",
        "\n",
        "transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transform)\n",
        "dataset2 = datasets.MNIST('../data', train=False,\n",
        "                    transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
        "\n",
        "model = Net().to(device)\n",
        "optimizer = optim.Adadelta(model.parameters(), lr=LR)\n",
        "\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=GAMMA)\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)\n",
        "    scheduler.step()\n",
        "\n",
        "torch.save(model, \"mnist_cnn.pt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we are adding the rest of the code that uploads the trained model to Cloud Storage bucket\n",
        "*(Note - run this cell only once as it appends code to the py file) *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bucket_name = os.environ['BUCKET_NAME']\n",
        "destination_blob_name = \"k8s-models/mnist_cnn.pt\"\n",
        "\n",
        "phyton_code = f\"\"\"\n",
        "# Upload the trained model to Cloud storage\n",
        "from google.cloud import storage\n",
        "\n",
        "storage_client = storage.Client()\n",
        "\n",
        "bucket = storage_client.bucket(\"{bucket_name}\")\n",
        "blob = bucket.blob(\"{destination_blob_name}\")\n",
        "\n",
        "blob.upload_from_filename(\"mnist_cnn.pt\")\n",
        "\n",
        "print(f\"Model uploaded to: gs://{bucket_name}/{destination_blob_name}\")\n",
        "\"\"\"\n",
        "\n",
        "with open('train.py', 'a') as f:\n",
        "     f.write(phyton_code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJE5DylbwBmw"
      },
      "source": [
        "### Dockerfile\n",
        "\n",
        "Kubernetes is built for running workloads that can be specified in Docker containers. The `Dockerfile` is a script used to build a container image, which is a lightweight and portable unit that can run applications and their dependencies in isolated environments.\n",
        "\n",
        "In our `Dockerfile`, we list the base image, the files we want to copy (eg `train.py`), install dependencies and set environment variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ND_IUMZiBYpc"
      },
      "outputs": [],
      "source": [
        "%%writefile Dockerfile\n",
        "\n",
        "FROM nvidia/cuda:12.2.0-runtime-ubuntu22.04\n",
        "\n",
        "RUN apt-get update && \\\n",
        "    apt-get -y --no-install-recommends install python3-dev gcc python3-pip git && \\\n",
        "    rm -rf /var/lib/apt/lists/*\n",
        "\n",
        "RUN pip3 install --no-cache-dir torch torchvision transformers peft datasets bitsandbytes protobuf scipy einops google-cloud-storage google-cloud-logging\n",
        "\n",
        "COPY train.py /train.py\n",
        "\n",
        "ENV PYTHONUNBUFFERED 1\n",
        "\n",
        "CMD python3 /train.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ID-fTeG_xB1V"
      },
      "source": [
        "### Respository\n",
        "\n",
        "We need a repository to host our Docker image. In this example, we will use GCP's [Artifact Registry](https://cloud.google.com/artifact-registry)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fycbJHyBY2L"
      },
      "outputs": [],
      "source": [
        "! gcloud artifacts repositories create pytorch-t4 \\\n",
        "    --project=$PROJECT_ID \\\n",
        "    --repository-format=docker \\\n",
        "    --location=us-central1 \\\n",
        "    --description=\"Docker repository\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heZGo6uTFL5x"
      },
      "source": [
        "You need to provide repository read access to the cluster otherwise you will get permission denied errors - https://cloud.google.com/kubernetes-engine/docs/troubleshooting#permission_denied_error\n",
        "Please use the Compute Engine default service account email to update the below command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhf5-X2TFL5x"
      },
      "outputs": [],
      "source": [
        "! gcloud artifacts repositories add-iam-policy-binding pytorch-t4 \\\n",
        "    --location=us-central1 \\\n",
        "    --member=serviceAccount:${GCE_SA_EMAIL} \\\n",
        "    --role=\"roles/artifactregistry.reader\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BabRm8rBY43"
      },
      "outputs": [],
      "source": [
        "! gcloud builds submit \\\n",
        "  --tag us-central1-docker.pkg.dev/$PROJECT_ID/pytorch-t4/mnist-train ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVL0E7cR6Xam"
      },
      "source": [
        "### YAML\n",
        "\n",
        "In the context of Kubernetes, a YAML (YAML Ain't Markup Language) file is a human-readable data serialization format used for configuration files. Kubernetes uses YAML files to define and configure resources such as pods, deployments, services, and more.\n",
        "\n",
        "The file typically contains a set of key-value pairs, where the keys represent the configuration options and the values represent their respective settings. The structure corresponds to the desired state of the  resources needed for a job.\n",
        "\n",
        "A YAML file for a basic Pod might look like this:\n",
        "\n",
        "```\n",
        "apiVersion: v1\n",
        "kind: Pod\n",
        "metadata:\n",
        "  name: example-pod\n",
        "spec:\n",
        "  containers:\n",
        "  - name: nginx-container\n",
        "    image: nginx:latest\n",
        "\n",
        "```\n",
        "\n",
        "We will see additional key-value pairs in the YAML necessary for our training job, including the job name, the docker image, and a graceful termination setting.\n",
        "\n",
        "YAML files are typically run with a `kubectl` command such as:\n",
        "\n",
        "`kubectl apply -f example-pod.yaml`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pipXnfYmwXRy"
      },
      "source": [
        "We create a yaml file to create our job with the image that we created in the artifact repositoy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbKkhL8TBY7k"
      },
      "outputs": [],
      "source": [
        "yaml_content = f\"\"\"\n",
        "apiVersion: batch/v1\n",
        "kind: Job\n",
        "metadata:\n",
        "  name: train-job-1\n",
        "spec:\n",
        "  backoffLimit: 2\n",
        "  template:\n",
        "    metadata:\n",
        "    spec:\n",
        "      terminationGracePeriodSeconds: 60\n",
        "      containers:\n",
        "      - name: mnist-train\n",
        "        image: us-central1-docker.pkg.dev/{PROJECT_ID}/pytorch-t4/mnist-train:latest\n",
        "        resources: \n",
        "          limits: \n",
        "            nvidia.com/gpu: 1 \n",
        "      restartPolicy: OnFailure \n",
        "\"\"\"\n",
        "\n",
        "print(yaml_content)\n",
        "\n",
        "with open('train.yaml', 'w') as f:\n",
        "     f.write(yaml_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggkuZh9j7bFC"
      },
      "source": [
        "### kubectl\n",
        "\n",
        "`kubectl` is the command-line tool used for interacting with Kubernetes clusters. It serves as the primary means for administrators, developers, and operators to manage Kubernetes clusters and work with the resources within them. The name \"Kube Control.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVrcQQKhRKJ1"
      },
      "source": [
        "Let's link `kubectl` to the cluster so we can start and check the training job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1DKmT9yukW2"
      },
      "outputs": [],
      "source": [
        "!gcloud container clusters get-credentials t4-demo \\\n",
        "    --location ${REGION}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qZyvvAU3pYQ"
      },
      "source": [
        "To use `kubectl` commands on our cluster, we have to make sure it's talking to the correct one. We can use the `set-context` command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnvgHmUpuIk9"
      },
      "outputs": [],
      "source": [
        "!kubectl config set-context t4-demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6idTyy43z5s"
      },
      "source": [
        "Get the basic info about the cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ai0wQo6luwnd"
      },
      "outputs": [],
      "source": [
        "!kubectl cluster-info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lejHzJqX33hu"
      },
      "source": [
        "Run, or 'apply' the training job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQBBxsNiFfUV"
      },
      "outputs": [],
      "source": [
        "!kubectl apply -f train.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5kTaE-Y38qj"
      },
      "source": [
        "See all jobs running"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAgGWxYPJtW1"
      },
      "outputs": [],
      "source": [
        "!kubectl get jobs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlW1k-_A3--7"
      },
      "source": [
        "Check the nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlJNNqydg2_m"
      },
      "outputs": [],
      "source": [
        "!kubectl get nodes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkXcY0uJ4AEF"
      },
      "source": [
        "Describe the training job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Rdt6kt5JxLV"
      },
      "outputs": [],
      "source": [
        "!kubectl describe job train-job-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxk0UolTXGk_"
      },
      "source": [
        "To inspect the pods running the job, replace the value below with the `Created pod: xxxxx` value above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBiaA6RdY15O"
      },
      "outputs": [],
      "source": [
        "!kubectl describe pod train-job-1-xxxxx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhcbWNSozDaA"
      },
      "source": [
        "Finally, check the model file is in the specified storage bucket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gvf2ez-y8Hn"
      },
      "outputs": [],
      "source": [
        "!gsutil ls gs://${BUCKET_NAME}/k8s-models/mnist_cnn.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KCipYw3iMqy"
      },
      "source": [
        "----------------------------------"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
